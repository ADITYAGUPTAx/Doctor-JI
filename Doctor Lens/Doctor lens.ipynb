{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69f855b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.12), please consider upgrading to the latest version (0.3.13).\n",
      "Path to dataset files: C:\\Users\\aditya\\.cache\\kagglehub\\datasets\\kmader\\skin-cancer-mnist-ham10000\\versions\\2\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"kmader/skin-cancer-mnist-ham10000\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8814772b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n",
    "for zip_name in [\"HAM10000_images_part_1.zip\", \"HAM10000_images_part_2.zip\"]:\n",
    "    zip_path = os.path.join(path, zip_name)\n",
    "    if os.path.exists(zip_path):\n",
    "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(path)\n",
    "            print(f\"Extracted {zip_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e07e9bec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/attr_value.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/resource_handle.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor_shape.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/types.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/full_type.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/function.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/node_def.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/op_def.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/graph_debug_info.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/versions.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at xla/tsl/protobuf/coordination_config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/cost_graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/step_stats.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/allocation_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/cluster.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\aditya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/debug.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, CSVLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c75dd392",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "012abb6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "DATA_DIR = Path(r\"C:\\Users\\aditya\\.cache\\kagglehub\\datasets\\kmader\\skin-cancer-mnist-ham10000\\versions\\2\")\n",
    "META_CSV = DATA_DIR / \"HAM10000_metadata.csv\"\n",
    "IMG_DIRS = [DATA_DIR / \"HAM10000_images_part_1\", DATA_DIR / \"HAM10000_images_part_2\"]\n",
    "ARTIFACTS_DIR = Path(\"artifacts\")\n",
    "ARTIFACTS_DIR.mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18667b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 30\n",
    "BASE_LR = 1e-4\n",
    "VAL_SPLIT = 0.15\n",
    "TEST_SPLIT = 0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17b4c051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading metadata…\n",
      "Resolving image paths…\n"
     ]
    }
   ],
   "source": [
    "assert META_CSV.exists(), f\"Metadata CSV not found at {META_CSV}\"\n",
    "for d in IMG_DIRS:\n",
    "    assert d.exists(), f\"Image directory not found: {d}\"\n",
    "\n",
    "\n",
    "print(\"Loading metadata…\")\n",
    "df = pd.read_csv(META_CSV)\n",
    "\n",
    "\n",
    "# Map image_id -> file path (look in both parts)\n",
    "print(\"Resolving image paths…\")\n",
    "image_paths = {}\n",
    "for img_dir in IMG_DIRS:\n",
    "    for fname in os.listdir(img_dir):\n",
    "        if fname.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n",
    "            key = Path(fname).stem # 'ISIC_XXXXX'\n",
    "            image_paths[key] = str(img_dir / fname)\n",
    "\n",
    "\n",
    "# Keep only rows whose image file exists\n",
    "df[\"filepath\"] = df[\"image_id\"].map(image_paths)\n",
    "df = df[~df[\"filepath\"].isnull()].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30ba196f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding labels…\n",
      "Classes: ['akiec', 'bcc', 'bkl', 'df', 'mel', 'nv', 'vasc']\n"
     ]
    }
   ],
   "source": [
    "df[\"filepath\"] = df[\"image_id\"].map(image_paths)\n",
    "df = df[~df[\"filepath\"].isnull()].copy()\n",
    "\n",
    "print(\"Encoding labels…\")\n",
    "le = LabelEncoder()\n",
    "df[\"label\"] = le.fit_transform(df[\"dx\"].values)\n",
    "num_classes = len(le.classes_)\n",
    "print(\"Classes:\", list(le.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a230d2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting dataset (stratified)…\n",
      "Train: 7010, Val: 1502, Test: 1503\n"
     ]
    }
   ],
   "source": [
    "print(\"Splitting dataset (stratified)…\")\n",
    "train_df, temp_df = train_test_split(\n",
    "df, test_size=(VAL_SPLIT + TEST_SPLIT), stratify=df[\"label\"], random_state=SEED\n",
    ")\n",
    "relative_val = VAL_SPLIT / (VAL_SPLIT + TEST_SPLIT)\n",
    "val_df, test_df = train_test_split(\n",
    "temp_df, test_size=(1 - relative_val), stratify=temp_df[\"label\"], random_state=SEED\n",
    ")\n",
    "\n",
    "\n",
    "print(f\"Train: {len(train_df)}, Val: {len(val_df)}, Test: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d59b5f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing class weights…\n",
      "Class weights: {0: np.float64(4.37305053025577), 1: np.float64(2.7817460317460316), 2: np.float64(1.3022478172023035), 3: np.float64(12.36331569664903), 4: np.float64(1.285530900421786), 5: np.float64(0.21338772031292808), 6: np.float64(10.115440115440116)}\n"
     ]
    }
   ],
   "source": [
    "print(\"Computing class weights…\")\n",
    "class_weights_array = compute_class_weight(\n",
    "class_weight=\"balanced\",\n",
    "classes=np.unique(train_df[\"label\"]),\n",
    "y=train_df[\"label\"].values,\n",
    ")\n",
    "class_weights = {i: w for i, w in enumerate(class_weights_array)}\n",
    "print(\"Class weights:\", class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c5a15e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "\n",
    "def decode_img(path):\n",
    "    img = tf.io.read_file(path)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    img = tf.image.resize(img, IMG_SIZE)\n",
    "    img = tf.cast(img, tf.float32)\n",
    "    img = preprocess_input(img) # ResNet50 preprocessing\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d7fe59ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmenter = tf.keras.Sequential([\n",
    "layers.RandomFlip(\"horizontal\"),\n",
    "layers.RandomRotation(0.1),\n",
    "layers.RandomZoom(0.1),\n",
    "layers.RandomContrast(0.1),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a76b8a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(df_, training=False):\n",
    "    paths = df_[\"filepath\"].values\n",
    "    labels = df_[\"label\"].values\n",
    "    ds = tf.data.Dataset.from_tensor_slices((paths, labels))\n",
    "    ds = ds.shuffle(len(df_), seed=SEED) if training else ds\n",
    "\n",
    "    def _load(path, label):\n",
    "        img = decode_img(path)\n",
    "        if training:\n",
    "            img = augmenter(img)  \n",
    "        label_onehot = tf.one_hot(label, num_classes)\n",
    "        return img, label_onehot\n",
    "\n",
    "    ds = ds.map(_load, num_parallel_calls=AUTOTUNE)\n",
    "    ds = ds.batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
    "    return ds\n",
    "\n",
    "train_ds = make_dataset(train_df, training=True)\n",
    "val_ds = make_dataset(val_df, training=False)\n",
    "test_ds = make_dataset(test_df, training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cc1fef04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model…\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ resnet50 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">23,587,712</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)              │        <span style=\"color: #00af00; text-decoration-color: #00af00\">14,343</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_2 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ resnet50 (\u001b[38;5;33mFunctional\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m2048\u001b[0m)     │    \u001b[38;5;34m23,587,712\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)              │        \u001b[38;5;34m14,343\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,602,055</span> (90.03 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m23,602,055\u001b[0m (90.03 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,480,007</span> (17.09 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,480,007\u001b[0m (17.09 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,122,048</span> (72.94 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m19,122,048\u001b[0m (72.94 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Building model…\")\n",
    "base_model = ResNet50(\n",
    "include_top=False,\n",
    "weights=\"imagenet\",\n",
    "input_shape=(*IMG_SIZE, 3)\n",
    ")\n",
    "for layer in base_model.layers[:-10]:\n",
    "    layer.trainable = False\n",
    "\n",
    "\n",
    "inputs = layers.Input(shape=(*IMG_SIZE, 3))\n",
    "x = base_model(inputs, training=False)\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
    "model = models.Model(inputs, outputs)\n",
    "\n",
    "\n",
    "model.compile(\n",
    "optimizer=tf.keras.optimizers.Adam(learning_rate=BASE_LR),\n",
    "loss=\"categorical_crossentropy\",\n",
    "metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d4fe0d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = ARTIFACTS_DIR / \"best_model.keras\"\n",
    "callbacks = [\n",
    "EarlyStopping(monitor=\"val_accuracy\", patience=6, restore_best_weights=True),\n",
    "ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=3, min_lr=1e-6),\n",
    "ModelCheckpoint(filepath=str(checkpoint_path), monitor=\"val_accuracy\", save_best_only=True),\n",
    "CSVLogger(str(ARTIFACTS_DIR / \"history.csv\"), append=False)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe683d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training (stage 1)…\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  8/220\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:46\u001b[0m 1s/step - accuracy: 0.0695 - loss: 3.7712"
     ]
    }
   ],
   "source": [
    "print(\"Training (stage 1)…\")\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=EPOCHS,\n",
    "    class_weight=class_weights,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5cbc83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Fine-tuning (stage 2)…\")\n",
    "for layer in base_model.layers[-50:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=BASE_LR * 0.2),\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "\n",
    "history_ft = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=max(8, EPOCHS // 2),\n",
    "    class_weight=class_weights,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf6a46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Evaluating on test set…\")\n",
    "loss, acc = model.evaluate(test_ds, verbose=0)\n",
    "print(f\"Test Accuracy: {acc:.4f} | Test Loss: {loss:.4f}\")\n",
    "\n",
    "\n",
    "# Predictions for detailed metrics\n",
    "print(\"Generating classification report…\")\n",
    "probs = model.predict(test_ds, verbose=0)\n",
    "y_true = np.concatenate([np.argmax(y.numpy(), axis=1) for _, y in test_ds], axis=0)\n",
    "y_pred = probs.argmax(axis=1)\n",
    "\n",
    "\n",
    "print(classification_report(y_true, y_pred, target_names=list(le.classes_)))\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6363cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "print(\"Saving artifacts…\")\n",
    "model.save(checkpoint_path) # ensure final model persisted\n",
    "with open(ARTIFACTS_DIR / \"label_map.json\", \"w\") as f:\n",
    "    json.dump({cls: int(idx) for idx, cls in enumerate(le.classes_)}, f, indent=2)\n",
    "\n",
    "\n",
    "print(\"Done. Artifacts saved in:\", ARTIFACTS_DIR.resolve())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27eec96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image(image_path: str):\n",
    "    \"\"\"Return (class_name, confidence) for a single image file.\"\"\"\n",
    "    img = tf.io.read_file(image_path)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    img = tf.image.resize(img, IMG_SIZE)\n",
    "    img = tf.cast(img, tf.float32)\n",
    "    img = preprocess_input(img)\n",
    "    img = tf.expand_dims(img, axis=0)\n",
    "    preds = model.predict(img, verbose=0)[0]\n",
    "    idx = int(np.argmax(preds))\n",
    "    class_name = le.classes_[idx]\n",
    "    conf = float(preds[idx])\n",
    "    return class_name, conf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
